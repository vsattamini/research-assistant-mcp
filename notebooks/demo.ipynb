{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Fixed code for Search Coordinator demo\n",
    "question3 = \"How effective are global health programs for malaria prevention in sub-Saharan Africa, and what do recent studies show about cost-effectiveness?\"\n",
    "\n",
    "print(f\"üåç Complex Research Question: {question3}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Use search coordinator for multi-source approach\n",
    "print(\"üîÑ Using Search Coordinator for multi-source research...\")\n",
    "\n",
    "# Create intelligent search plan\n",
    "search_plans = assistant['search_coordinator'].plan_searches(question3, focus=\"\")\n",
    "print(f\"\\nüìã Search Plan Created:\")\n",
    "print(f\"   ‚Ä¢ Search strategies: {len(search_plans)}\")\n",
    "\n",
    "# Execute searches (using the first plan as an example)\n",
    "search_results = assistant['search_coordinator'].execute_search_plan(search_plans[0]) if search_plans else None\n",
    "if search_results:\n",
    "    print(f\"   ‚Ä¢ Web results: {len(search_results.web_results)}\")\n",
    "    print(f\"   ‚Ä¢ Academic results: {len(search_results.arxiv_results)}\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No search results generated\")\n",
    "\n",
    "# Run full MCP research\n",
    "result3 = assistant['mcp_simulator'].run_research(question3)\n",
    "\n",
    "print(\"\\nüìã Multi-Source Research Result:\")\n",
    "print(result3.get('answer', 'No answer generated'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1dc9a7",
   "metadata": {},
   "source": [
    "## Expected Outputs\n",
    "\n",
    "- **Cell 1-3**: Setup confirmation messages\n",
    "- **Cell 4**: Basic research answer with sources\n",
    "- **Cell 5**: Academic paper results + comprehensive analysis  \n",
    "- **Cell 6**: Multi-source research with web + academic sources\n",
    "- **Cell 7**: Caching demonstration with similarity scores\n",
    "- **Cell 8**: Task breakdown visualization showing MCP workflow\n",
    "- **Cell 9**: Document processing analysis results\n",
    "- **Cell 10**: Summary statistics and feature checklist\n",
    "\n",
    "This notebook demonstrates all core assignment requirements plus bonus features like source citations, reasoning steps, and multi-source orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e4171",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db02cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Detected project root: /home/vlofgren/Documents/Projects/research-assistant-mcp\n",
      "üîß Added to Python path:\n",
      "   ‚Ä¢ /home/vlofgren/Documents/Projects/research-assistant-mcp\n",
      "   ‚Ä¢ /home/vlofgren/Documents/Projects/research-assistant-mcp/src\n",
      "‚úÖ All imports successful using src-relative imports!\n",
      "üìÅ Working directory: /home/vlofgren/Documents/Projects/research-assistant-mcp\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path for imports\n",
    "# Navigate up from notebooks/ to project root\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "print(f\"üìÅ Detected project root: {project_root}\")\n",
    "\n",
    "# Add both project root and src directory to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"üîß Added to Python path:\")\n",
    "print(f\"   ‚Ä¢ {project_root}\")\n",
    "print(f\"   ‚Ä¢ {src_path}\")\n",
    "\n",
    "# Import core components\n",
    "try:\n",
    "    from models.model_builder import ModelBuilder\n",
    "    from orchestration.mcp_simulator import MCPSimulator\n",
    "    from orchestration.search_coordinator import SearchCoordinator\n",
    "    from tools.web_search import WebSearchTool\n",
    "    from tools.arxiv_search import ArxivSearchTool\n",
    "    from tools.vector_db import VectorDBTool\n",
    "    from utils.document_processor import DocumentProcessor\n",
    "    print(\"‚úÖ All imports successful using src-relative imports!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error with src-relative imports: {e}\")\n",
    "    # Fallback to absolute imports if running from project root\n",
    "    try:\n",
    "        from src.models.model_builder import ModelBuilder\n",
    "        from src.orchestration.mcp_simulator import MCPSimulator\n",
    "        from src.orchestration.search_coordinator import SearchCoordinator\n",
    "        from src.tools.web_search import WebSearchTool\n",
    "        from src.tools.arxiv_search import ArxivSearchTool\n",
    "        from src.tools.vector_db import VectorDBTool\n",
    "        from src.utils.document_processor import DocumentProcessor\n",
    "        print(\"‚úÖ All imports successful using absolute src imports!\")\n",
    "    except ImportError as e2:\n",
    "        print(f\"‚ùå Import error with absolute imports: {e2}\")\n",
    "        print(\"üîç Please ensure you're running from the project root or notebooks directory\")\n",
    "        print(f\"   Current working directory: {Path.cwd()}\")\n",
    "        print(f\"   Project structure expected:\")\n",
    "        print(f\"     project_root/\")\n",
    "        print(f\"       ‚îú‚îÄ‚îÄ src/\")\n",
    "        print(f\"       ‚îÇ   ‚îú‚îÄ‚îÄ models/\")\n",
    "        print(f\"       ‚îÇ   ‚îú‚îÄ‚îÄ orchestration/\")\n",
    "        print(f\"       ‚îÇ   ‚îî‚îÄ‚îÄ tools/\")\n",
    "        print(f\"       ‚îî‚îÄ‚îÄ notebooks/\")\n",
    "        raise\n",
    "\n",
    "print(f\"üìÅ Working directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6959d1b",
   "metadata": {},
   "source": [
    "### Setup 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db889fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë API Key Status:\n",
      "   OpenAI: ‚úÖ Set\n",
      "   Tavily: ‚úÖ Set\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"üîë API Key Status:\")\n",
    "print(f\"   OpenAI: {'‚úÖ Set' if openai_key else '‚ùå Missing'}\")\n",
    "print(f\"   Tavily: {'‚úÖ Set' if tavily_key else '‚ùå Missing (web search will use fallback)'}\")\n",
    "\n",
    "if not openai_key:\n",
    "    print(\"\\n‚ö†Ô∏è  To get full functionality, set OPENAI_API_KEY in your .env file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Research Assistant Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf2dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.model_builder:Model built successfully with provider: openai\n",
      "INFO:tools.web_search:Tavily client initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing Research Assistant Components...\n",
      "   ‚úÖ Model Builder configured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:tools.web_search:Insight extraction model loaded.\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:tools.arxiv_search:ArXiv insight extraction model loaded.\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Search tools initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tools.vector_db:VectorDBTool initialised (provider=openai, collection='research_assistant', dir='data/vector_db')\n",
      "INFO:src.tools.web_search:Tavily client initialized successfully\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.web_search:Insight extraction model loaded.\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.arxiv_search:ArXiv insight extraction model loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Vector database connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.intelligent_search_planner:Model builder initialized for search planning\n",
      "INFO:orchestration.mcp_simulator:Search coordinator initialized successfully\n",
      "INFO:src.tools.web_search:Tavily client initialized successfully\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.web_search:Insight extraction model loaded.\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.arxiv_search:ArXiv insight extraction model loaded.\n",
      "INFO:src.models.model_builder:Model built successfully with provider: openai\n",
      "INFO:src.tools.intelligent_search_planner:Model builder initialized for search planning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ MCP Simulator ready\n",
      "   ‚úÖ Search Coordinator initialized\n",
      "\n",
      "üöÄ Research Assistant is ready for demo!\n"
     ]
    }
   ],
   "source": [
    "def create_demo_research_assistant():\n",
    "    \"\"\"Create and configure the research assistant for demo.\"\"\"\n",
    "    \n",
    "    print(\"üîß Initializing Research Assistant Components...\")\n",
    "    \n",
    "    # 1. Create model builder\n",
    "    model = (ModelBuilder()\n",
    "            .with_provider(\"openai\")\n",
    "            .with_model(\"gpt-4o-mini\")\n",
    "            .with_temperature(0.7)\n",
    "            .with_max_tokens(1000)\n",
    "            .with_system_prompt(\"\"\"You are an expert research assistant using MCP workflow.\n",
    "            Provide clear, comprehensive responses with proper citations and structured analysis.\"\"\")\n",
    "            .build())\n",
    "    print(\"   ‚úÖ Model Builder configured\")\n",
    "    \n",
    "    # 2. Initialize tools\n",
    "    web_search_tool = WebSearchTool(api_key=tavily_key)\n",
    "    arxiv_tool = ArxivSearchTool()\n",
    "    document_processor = DocumentProcessor()\n",
    "    print(\"   ‚úÖ Search tools initialized\")\n",
    "    \n",
    "    # 3. Vector database for caching\n",
    "    vector_db = VectorDBTool(persist_directory=\"data/vector_db\")\n",
    "    print(\"   ‚úÖ Vector database connected\")\n",
    "    \n",
    "    # 4. MCP simulator (orchestrator)\n",
    "    mcp_simulator = MCPSimulator(model, vector_db=vector_db)\n",
    "    print(\"   ‚úÖ MCP Simulator ready\")\n",
    "    \n",
    "    # 5. Search coordinator\n",
    "    search_coordinator = SearchCoordinator(\n",
    "        web_api_key=tavily_key,\n",
    "        openai_api_key=openai_key\n",
    "    )\n",
    "    print(\"   ‚úÖ Search Coordinator initialized\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'mcp_simulator': mcp_simulator,\n",
    "        'web_search': web_search_tool,\n",
    "        'arxiv_search': arxiv_tool,\n",
    "        'document_processor': document_processor,\n",
    "        'vector_db': vector_db,\n",
    "        'search_coordinator': search_coordinator\n",
    "    }\n",
    "\n",
    "# Initialize the assistant\n",
    "assistant = create_demo_research_assistant()\n",
    "print(\"\\nüöÄ Research Assistant is ready for demo!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb1709",
   "metadata": {},
   "source": [
    "### Demo 1 - Simple Research Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c3f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestration.mcp_simulator:Created research session: session_20250730_075445_4050\n",
      "INFO:orchestration.mcp_simulator:Created research session: session_20250730_075445_4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Research Question: What are the latest developments in quantum computing for 2024?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:Planning tasks for question: What are the latest developments in quantum computing for 2024?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:4 tasks planned\n",
      "INFO:orchestration.mcp_simulator:Planned 4 tasks for question using TaskPlannerTool\n",
      "INFO:orchestration.mcp_simulator:Executing task task_1: Search for recent articles, papers, and news about developments in quantum computing in 2024.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:src.tools.intelligent_search_planner:Structured analysis failed: 'arxiv_suitable' is not a valid SearchStrategy. Using fallback.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.search_coordinator:Intelligent analysis: Domain=technology, ArXiv suitable=True, Confidence=0.7\n",
      "INFO:src.tools.web_search:Search completed: 15 results found\n",
      "INFO:orchestration.search_coordinator:Performing ArXiv search - validated by intelligent analysis\n",
      "INFO:src.tools.arxiv_search:ArXiv search completed: 10 results found\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MetaCLIP 2: A Worldwide Scaling Recipe\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 61158 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MOVE: Motion-Guided Few-Shot Video Object Segmentation\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 51081 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Multiscale complexity of two-dimensional Ising systems with short-range,   ferromagnetic interactions\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 79921 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: StepAL: Step-aware Active Learning for Cataract Surgical Videos\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 28269 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image   Generative Models Great Again\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 62746 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MetaLab: Few-Shot Game Changer for Image Recognition\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 48402 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: $p$-integrability\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 12985 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Quantum and Material Effects in Undulator-Based LSW Searches for Dark   Photons\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 55844 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Pitfalls when tackling the exponential concentration of parameterized   quantum models\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 98459 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Foundation Models for Demand Forecasting via Dual-Strategy Ensembling\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 55489 characters from PDF\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 520 \"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.397695 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Search completed: 15 web + 10 arxiv results\n",
      "INFO:orchestration.mcp_simulator:Task task_1 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_2: Extract key advancements, breakthroughs, and new technologies from the gathered sources.\n",
      "INFO:orchestration.mcp_simulator:All search results are already processed; skipping extraction task task_2\n",
      "INFO:orchestration.mcp_simulator:Task task_2 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_3: Summarize the main trends and significant developments in quantum computing for 2024.\n",
      "INFO:orchestration.mcp_simulator:Skipping summarization task task_3 because synthesis handles aggregation\n",
      "INFO:orchestration.mcp_simulator:Task task_3 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_4: Compile a comprehensive report on the latest developments in quantum computing for 2024.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Task task_4 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Research session session_20250730_075445_4050 completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Final Answer:\n",
      "# Comprehensive Report on the Latest Developments in Quantum Computing for 2024\n",
      "\n",
      "### Introduction\n",
      "Quantum computing continues to evolve rapidly, with significant advancements and trends emerging in 2024. This report synthesizes key findings from recent research and developments in the field, highlighting innovations in hardware, algorithms, applications, and community engagement.\n",
      "\n",
      "### Key Developments in Quantum Computing for 2024\n",
      "\n",
      "1. **Advancements in Error Correction and Hardware**\n",
      "   - A major breakthrough was the announcement of Google's Willow quantum chip, which significantly enhances error correction capabilities as the number of qubits increases. This advancement addresses a longstanding challenge in quantum hardware, essential for developing reliable and scalable quantum systems [ACM A Quantum Leap Forward ‚Äì Communications of the ACM](https://cacm.acm.org/news/a-quantum-leap-forward/) - Source Type: web. \n",
      "   - Companies like Quantinuum are also making strides in fault-tolerant quantum computing, emphasizing the importance of reliability and stability in quantum systems [IEEE Spectrum Fault Tolerant Quantum Computing: Quantinuum's advance - IEEE Spectrum](https://spectrum.ieee.org/quantinuum-fault-tolerant-quantum-computing) - Source Type: web.\n",
      "\n",
      "2. **Innovations in Quantum Algorithms and Applications**\n",
      "   - Research is intensifying on the application of quantum computing across various sectors. For instance, quantum computing is being leveraged in medical sciences for improved computation, optimization, security, and machine learning [Quantum computing research in medical sciences](https://www.sciencedirect.com/science/article/pii/S2352914824001631) - Source Type: web.\n",
      "   - Notably, advancements in superfluorescent sources are being engineered to enhance quantum information applications, showcasing the potential transformative impact of such technologies [The future of quantum technologies: superfluorescence ...](https://pubmed.ncbi.nlm.nih.gov/39635086/) - Source Type: web.\n",
      "   - The use of magnons as a platform for hybrid quantum technologies indicates a diversification of approaches in quantum hardware [Using magnons as a quantum technology platform](https://pubmed.ncbi.nlm.nih.gov/39059434/) - Source Type: web.\n",
      "\n",
      "3. **Integration with Sustainability and Industry 4.0**\n",
      "   - Quantum computing technologies are increasingly seen as enablers for sustainable practices within the circular economy. Research indicates that quantum applications can significantly improve supply chain management efficiency, aligning with the goals of Industry 4.0 [Quantum Computing as an Enabler for sustainable Circular ...](https://www.sciencedirect.com/science/article/pii/S3050607725000273) - Source Type: web.\n",
      "   - There is a growing interest in exploring the relationships between renewable energy sectors and emerging technologies, emphasizing the long-term dynamics within these fields [Dynamic connectedness of quantum computing, artificial ...](https://www.sciencedirect.com/science/article/abs/pii/S0140988324007254) - Source Type: web.\n",
      "\n",
      "4. **Active Research and Community Engagement**\n",
      "   - Upcoming events such as IEEE Quantum Week 2024, scheduled for September 29, 2024, reflect the active engagement within the quantum computing community, providing platforms for researchers, educators, and entrepreneurs to discuss challenges and opportunities [IEEE Quantum Week QCE24 News and Updates ‚Äì IEEE Quantum Week](https://qce.quantum.ieee.org/2024/qce/news/) - Source Type: web.\n",
      "   - The increasing number of publications and citations in quantum computing research indicates a vibrant academic interest and the growing recognition of quantum technologies' potential across various disciplines [Perspective Transforming research with quantum computing](https://www.sciencedirect.com/science/article/pii/S2949948824000295) - Source Type: web.\n",
      "\n",
      "5. **Global and Media Coverage**\n",
      "   - Major news outlets like The New York Times are providing extensive coverage of advancements in quantum computing, reflecting its rising profile in public discourse and policy discussions [The New York Times - Breaking News, US News, World News and ...](https://www.nytimes.com/) - Source Type: web.\n",
      "\n",
      "### Conclusion and Future Outlook\n",
      "2024 marks a pivotal year for quantum computing, characterized by breakthroughs in hardware reliability, enhanced applications across diverse fields, and increased global engagement to harness quantum technologies' transformative potential. As the field progresses, ongoing research will likely focus on refining error correction techniques, expanding practical applications, and fostering interdisciplinary collaboration.\n",
      "\n",
      "### References\n",
      "1. [Perspective Transforming research with quantum computing](https://www.sciencedirect.com/science/article/pii/S2949948824000295) - Source Type: web\n",
      "2. [The New York Times - Breaking News, US News, World News and ...](https://www.nytimes.com/) - Source Type: web\n",
      "3. [The future of quantum technologies: superfluorescence ...](https://pubmed.ncbi.nlm.nih.gov/396350\n",
      "\n",
      "üìä Research Statistics:\n",
      "   ‚Ä¢ Session ID: session_20250730_075445_4050\n",
      "   ‚Ä¢ Sources found: 25\n",
      "   ‚Ä¢ Reasoning steps: 4\n"
     ]
    }
   ],
   "source": [
    "question1 = \"What are the latest developments in quantum computing for 2024?\"\n",
    "\n",
    "print(f\"üî¨ Research Question: {question1}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run research using MCP simulator\n",
    "session_id = assistant['mcp_simulator'].create_session(question1)\n",
    "result1 = assistant['mcp_simulator'].run_research(question1)\n",
    "\n",
    "print(\"\\nüìã Final Answer:\")\n",
    "print(result1.get('answer', 'No answer generated'))\n",
    "\n",
    "print(f\"\\nüìä Research Statistics:\")\n",
    "print(f\"   ‚Ä¢ Session ID: {session_id}\")\n",
    "print(f\"   ‚Ä¢ Sources found: {len(result1.get('sources', []))}\")\n",
    "print(f\"   ‚Ä¢ Reasoning steps: {len(result1.get('reasoning_steps', []))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6be489",
   "metadata": {},
   "source": [
    "### Demo 2 - Academic Research with ArXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e524f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Academic Research Question: What are the most significant machine learning breakthroughs in natural language processing from recent academic papers?\n",
      "================================================================================\n",
      "üîç Searching ArXiv for recent papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tools.arxiv_search:ArXiv search completed: 10 results found\n",
      "INFO:tools.arxiv_search:Downloading PDF for: MetaCLIP 2: A Worldwide Scaling Recipe\n",
      "INFO:tools.arxiv_search:Successfully extracted 61158 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: StepAL: Step-aware Active Learning for Cataract Surgical Videos\n",
      "INFO:tools.arxiv_search:Successfully extracted 28269 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image   Generative Models Great Again\n",
      "INFO:tools.arxiv_search:Successfully extracted 62746 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: MetaLab: Few-Shot Game Changer for Image Recognition\n",
      "INFO:tools.arxiv_search:Successfully extracted 48402 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: Pitfalls when tackling the exponential concentration of parameterized   quantum models\n",
      "INFO:tools.arxiv_search:Successfully extracted 98459 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: Foundation Models for Demand Forecasting via Dual-Strategy Ensembling\n",
      "INFO:tools.arxiv_search:Successfully extracted 55489 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos\n",
      "INFO:tools.arxiv_search:Successfully extracted 47222 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: DataSway: Vivifying Metaphoric Visualization with Animation Clip   Generation and Coordination\n",
      "INFO:tools.arxiv_search:Successfully extracted 113926 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router\n",
      "INFO:tools.arxiv_search:Successfully extracted 75598 characters from PDF\n",
      "INFO:tools.arxiv_search:Downloading PDF for: Validating Generative Agent-Based Models of Social Norm Enforcement:   From Replication to Novel Predictions\n",
      "INFO:tools.arxiv_search:Successfully extracted 51367 characters from PDF\n",
      "INFO:orchestration.mcp_simulator:Created research session: session_20250730_080131_9671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Found 10 recent papers:\n",
      "   1. MetaCLIP 2: A Worldwide Scaling Recipe...\n",
      "      Authors: Yung-Sung Chuang, Yang Li...\n",
      "      Published: 2025-07-29T17:59:58Z\n",
      "\n",
      "   2. StepAL: Step-aware Active Learning for Cataract Surgical Videos...\n",
      "      Authors: Nisarg A. Shah, Bardia Safaei...\n",
      "      Published: 2025-07-29T17:59:14Z\n",
      "\n",
      "   3. X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image   Generative ...\n",
      "      Authors: Zigang Geng, Yibing Wang...\n",
      "      Published: 2025-07-29T17:59:04Z\n",
      "\n",
      "üß† Running comprehensive research with MCP workflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:Planning tasks for question: What are the most significant machine learning breakthroughs in natural language processing from recent academic papers?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:4 tasks planned\n",
      "INFO:orchestration.mcp_simulator:Planned 4 tasks for question using TaskPlannerTool\n",
      "INFO:orchestration.mcp_simulator:Executing task task_1: Search for recent academic papers on machine learning breakthroughs in natural language processing.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.search_coordinator:Intelligent analysis: Domain=technology, ArXiv suitable=True, Confidence=0.9\n",
      "INFO:src.tools.web_search:Search completed: 15 results found\n",
      "INFO:orchestration.search_coordinator:Performing ArXiv search - validated by intelligent analysis\n",
      "INFO:src.tools.arxiv_search:ArXiv search completed: 10 results found\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MetaCLIP 2: A Worldwide Scaling Recipe\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 61158 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MOVE: Motion-Guided Few-Shot Video Object Segmentation\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 51081 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Multiscale complexity of two-dimensional Ising systems with short-range,   ferromagnetic interactions\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 79921 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: StepAL: Step-aware Active Learning for Cataract Surgical Videos\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 28269 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image   Generative Models Great Again\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 62746 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: MetaLab: Few-Shot Game Changer for Image Recognition\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 48402 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: $p$-integrability\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 12985 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Quantum and Material Effects in Undulator-Based LSW Searches for Dark   Photons\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 55844 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Pitfalls when tackling the exponential concentration of parameterized   quantum models\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 98459 characters from PDF\n",
      "INFO:src.tools.arxiv_search:Downloading PDF for: Foundation Models for Demand Forecasting via Dual-Strategy Ensembling\n",
      "INFO:src.tools.arxiv_search:Successfully extracted 55489 characters from PDF\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Search completed: 15 web + 10 arxiv results\n",
      "INFO:orchestration.mcp_simulator:Task task_1 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_2: Extract key breakthroughs and their significance from the identified papers.\n",
      "INFO:orchestration.mcp_simulator:All search results are already processed; skipping extraction task task_2\n",
      "INFO:orchestration.mcp_simulator:Task task_2 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_3: Summarize the most significant breakthroughs and their impact on the field.\n",
      "INFO:orchestration.mcp_simulator:Skipping summarization task task_3 because synthesis handles aggregation\n",
      "INFO:orchestration.mcp_simulator:Task task_3 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_4: Compile a comprehensive report on the most significant recent breakthroughs in NLP.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Task task_4 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Research session session_20250730_080131_9671 completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Comprehensive Research Result:\n",
      "# Comprehensive Report on Significant Machine Learning Breakthroughs in Natural Language Processing\n",
      "\n",
      "## Introduction\n",
      "Recent advancements in machine learning (ML), particularly in natural language processing (NLP), have transformed how machines understand and interact with human language. This report synthesizes findings from various academic sources to identify and analyze the most significant breakthroughs in NLP driven by ML.\n",
      "\n",
      "## Key Breakthroughs in NLP\n",
      "\n",
      "### 1. Transformer Architecture\n",
      "The introduction of the Transformer architecture represents a pivotal breakthrough in NLP, enabling substantial improvements in tasks such as language understanding, translation, and generation. This architecture has become the foundation for state-of-the-art NLP systems, facilitating parallelization and increasing training efficiency compared to previous models like RNNs and LSTMs. The emphasis on self-attention mechanisms allows models to weigh the importance of different words in a contextually relevant manner, significantly enhancing performance across various applications [The Evolution and Breakthrough of Natural Language Processing](https://dl.acm.org/doi/10.1145/3708036.3708089) - Web.\n",
      "\n",
      "### 2. Deep Learning Techniques\n",
      "Deep learning has increasingly been applied to NLP tasks, leading to the development of more sophisticated models capable of handling nuanced language understanding, sentiment analysis, and contextual comprehension. These advancements are driving the frontier of AI research in NLP, with a focus on creating models that can interpret and generate human-like text [Survey on Advancements in Machine Learning for Natural Language Processing](https://www.researchgate.net/publication/386168361_Survey_on_Advancements_in_Machine_Learning_for_Natural_Language_Processing) - Web.\n",
      "\n",
      "### 3. Hybrid and Advanced Methodologies\n",
      "Recent studies have highlighted the effectiveness of hybrid approaches, such as combining traditional methods like TF-IDF with neural networks, which have achieved accuracy rates of up to 95.8% in tasks like term importance classification. This trend suggests ongoing innovation in NLP methodologies, integrating various techniques to enhance overall performance [advances in natural language processing: a survey of techniques](https://www.researchgate.net/publication/385022656_ADVANCES_IN_NATURAL_LANGUAGE_PROCESSING_A_SURVEY_OF_TECHNIQUES) - Web.\n",
      "\n",
      "### 4. Enhanced Applications and Use Cases\n",
      "Recent advancements have significantly improved various applications of NLP:\n",
      "- **Voice Assistants and Chatbots**: Enhanced NLP capabilities have led to more intelligent and responsive voice-based interfaces, improving user interaction with technology [Advancements in Natural Language Processing (NLP) and Its Applications in Voice Assistants and Chatbots](https://www.researchgate.net/publication/381790528_Advancements_in_Natural_Language_Processing_NLP_and_Its_Applications_in_Voice_Assistants_and_Chatbots) - Web.\n",
      "- **Speech Recognition and Translation**: Machine learning models have greatly improved the accuracy and contextual understanding in these areas, making communication across languages more seamless [The Application of Machine Learning to Natural Language Processing](https://ieeexplore.ieee.org/document/10803211/) - Web.\n",
      "- **Sentiment Analysis and Text Comprehension**: Enhanced analytical models allow for more nuanced interpretations of human language, benefiting various sectors from marketing to mental health [Advancements in Natural Language Processing: A Comprehensive Review](https://www.researchgate.net/publication/380762601_Advancements_in_Natural_Language_Processing_A_Comprehensive_Review) - Web.\n",
      "\n",
      "### 5. Intersection of ML and NLP\n",
      "The convergence of ML techniques with NLP technologies is fostering the development of adaptive systems capable of human-like language understanding and generation. This integration is driving the creation of more sophisticated language processing systems that can perform tasks previously deemed challenging for AI [Exploring the Intersection of Machine Learning and Natural Language Processing](https://www.researchgate.net/publication/387428620_Exploring_the_Intersection_of_Machine_Learning_and_Natural_Language_Processing) - Web.\n",
      "\n",
      "### 6. Challenges and Future Directions\n",
      "Current research emphasizes the need to address challenges such as model interpretability, data limitations, and computational efficiency. Understanding the broader implications of NLP advancements is also crucial, especially regarding their impact on education, research, and service delivery [Advancements in natural language processing: Implications](https://www.sciencedirect.com/science/article/pii/S2772503024000598) - Web.\n",
      "\n",
      "## Trends and Future Directions\n",
      "Several emerging trends are shaping the future of NLP:\n",
      "- The integration of large language models (LLMs) into various applications, enhancing their capabilities [Deep learning-based natural language processing in human‚Äìagent](https://www.sciencedirect.com/science/article/pii/S2949719124000608) - Web.\n",
      "- Continuous refinement of algorithms and models to address existing limitations and expand NLP applications, particularly in non-English languages and diverse cultural contexts [A Study on The Role of Machine Learning in Natural Language Processing](https://www.researchgate.net/publication/363\n"
     ]
    }
   ],
   "source": [
    "question2 = \"What are the most significant machine learning breakthroughs in natural language processing from recent academic papers?\"\n",
    "\n",
    "print(f\"üéì Academic Research Question: {question2}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# First, let's search ArXiv directly to show the tool\n",
    "print(\"üîç Searching ArXiv for recent papers...\")\n",
    "arxiv_results = assistant['arxiv_search'].search_recent_papers(\n",
    "    \"machine learning natural language processing breakthrough\", \n",
    "    days_back=60,\n",
    ")\n",
    "\n",
    "print(f\"\\nüìö Found {len(arxiv_results)} recent papers:\")\n",
    "for i, paper in enumerate(arxiv_results[:3], 1):\n",
    "    print(f\"   {i}. {paper.title[:80]}...\")\n",
    "    print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "    print(f\"      Published: {paper.published_date}\")\n",
    "    print()\n",
    "\n",
    "# Now run full research\n",
    "print(\"üß† Running comprehensive research with MCP workflow...\")\n",
    "result2 = assistant['mcp_simulator'].run_research(question2)\n",
    "\n",
    "print(\"\\nüìã Comprehensive Research Result:\")\n",
    "print(result2.get('answer', 'No answer generated'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9fe030",
   "metadata": {},
   "source": [
    " ### Demo 3 - Complex Multi-Source Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e769e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Complex Research Question: How effective are global health programs for malaria prevention in sub-Saharan Africa, and what do recent studies show about cost-effectiveness?\n",
      "==========================================================================================\n",
      "üîÑ Using Search Coordinator for multi-source research...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.search_coordinator:Created 2 intelligent search plans for domain: SearchDomain.MEDICINE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Search Plan Created:\n",
      "   ‚Ä¢ Search strategies: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.tools.web_search:Search completed: 10 results found\n",
      "INFO:orchestration.search_coordinator:Search executed: 10 web + 0 arxiv results\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Created research session: session_20250730_082826_5837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚Ä¢ Web results: 10\n",
      "   ‚Ä¢ Academic results: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:Planning tasks for question: How effective are global health programs for malaria prevention in sub-Saharan Africa, and what do recent studies show about cost-effectiveness?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:tools.task_planner:7 tasks planned\n",
      "INFO:orchestration.mcp_simulator:Planned 7 tasks for question using TaskPlannerTool\n",
      "INFO:orchestration.mcp_simulator:Executing task task_1: Search for recent studies and reviews on the effectiveness of global health programs for malaria prevention in sub-Saharan Africa.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.search_coordinator:Intelligent analysis: Domain=medicine, ArXiv suitable=False, Confidence=0.9\n",
      "INFO:src.tools.web_search:Search completed: 15 results found\n",
      "INFO:orchestration.search_coordinator:Skipping ArXiv search - not suitable for domain: medicine\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Search completed: 15 web + 0 arxiv results\n",
      "INFO:orchestration.mcp_simulator:Task task_1 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_2: Search for recent studies and reviews on the cost-effectiveness of malaria prevention programs in sub-Saharan Africa.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.search_coordinator:Intelligent analysis: Domain=medicine, ArXiv suitable=False, Confidence=0.9\n",
      "INFO:src.tools.web_search:Search completed: 15 results found\n",
      "INFO:orchestration.search_coordinator:Skipping ArXiv search - not suitable for domain: medicine\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Search completed: 15 web + 0 arxiv results\n",
      "INFO:orchestration.mcp_simulator:Task task_2 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_3: Extract key findings from the identified studies regarding effectiveness and cost-effectiveness.\n",
      "INFO:orchestration.mcp_simulator:All search results are already processed; skipping extraction task task_3\n",
      "INFO:orchestration.mcp_simulator:Task task_3 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_4: Summarize the main conclusions from the recent studies on the effectiveness of malaria prevention programs.\n",
      "INFO:orchestration.mcp_simulator:Skipping summarization task task_4 because synthesis handles aggregation\n",
      "INFO:orchestration.mcp_simulator:Task task_4 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_5: Summarize the main conclusions from the recent studies on the cost-effectiveness of malaria prevention programs.\n",
      "INFO:orchestration.mcp_simulator:Skipping summarization task task_5 because synthesis handles aggregation\n",
      "INFO:orchestration.mcp_simulator:Task task_5 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_6: Synthesize the information on effectiveness and cost-effectiveness to provide an overall assessment.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Task task_6 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Executing task task_7: Prepare a comprehensive report on the effectiveness and cost-effectiveness of global health programs for malaria prevention in sub-Saharan Africa based on recent studies.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestration.mcp_simulator:Task task_7 completed successfully\n",
      "INFO:orchestration.mcp_simulator:Research session session_20250730_082826_5837 completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Multi-Source Research Result:\n",
      "# Effectiveness and Cost-Effectiveness of Global Health Programs for Malaria Prevention in Sub-Saharan Africa\n",
      "\n",
      "## Introduction\n",
      "Malaria remains a significant public health threat in sub-Saharan Africa, necessitating ongoing global health interventions. This report synthesizes recent studies to evaluate the effectiveness and cost-effectiveness of malaria prevention strategies in the region, highlighting key findings and trends.\n",
      "\n",
      "## Effectiveness of Malaria Prevention Programs\n",
      "\n",
      "### 1. **Interventions**\n",
      "- **Vector Control**: The distribution of insecticide-treated nets (ITNs) has been pivotal in reducing malaria cases. The cost-effectiveness of ITNs ranges from **US$19 to US$85 per disability-adjusted life year (DALY) averted**, making them central to malaria prevention efforts. Insecticide treatment alone is particularly cost-effective, costing **US$4-10 per DALY averted**. Residual spraying has a higher cost-effectiveness at **US$32-58 per DALY averted** [Cost-effectiveness of malaria control in sub-Saharan Africa](https://pubmed.ncbi.nlm.nih.gov/10437867/) - Web.\n",
      "\n",
      "- **Chemoprevention**: This approach is effective in both children and pregnant women. The cost-effectiveness for children's chemoprophylaxis is **US$3-12 per DALY averted**, while intermittent treatment for pregnant women costs **US$4-29 per DALY averted** [Cost-effectiveness of malaria control in sub-Saharan Africa](https://pubmed.ncbi.nlm.nih.gov/10437867/) - Web.\n",
      "\n",
      "- **Health Education**: Health education strategies have shown moderate effectiveness in increasing malaria knowledge and ITN usage among populations, indicating that behavioral interventions are critical components of prevention strategies [systematic review and meta-analysis](https://pubmed.ncbi.nlm.nih.gov/37601202/) - Web.\n",
      "\n",
      "- **Emerging Interventions**: The RTS,S malaria vaccine shows promise as a cost-effective intervention, with a cost threshold of less than **US$9.30 per dose** needed to ensure high efficiency [Modelling the relative cost-effectiveness of the RTS,S/AS01](https://pubmed.ncbi.nlm.nih.gov/37080831/) - Web.\n",
      "\n",
      "### 2. **Overall Progress**\n",
      "Significant reductions in malaria incidence (40% from 2000 to 2022) and mortality (60% during the same period) have been documented, reflecting the positive impact of integrated malaria control strategies [Current Status of Malaria Control and Elimination in Africa](https://link.springer.com/article/10.1007/s44197-024-00228-2) - Web.\n",
      "\n",
      "## Cost-Effectiveness of Malaria Prevention Programs\n",
      "\n",
      "### 1. **Cost Analysis**\n",
      "- The cost-effectiveness of various malaria interventions varies significantly. For instance, case management strategies are highly cost-effective, with costs as low as **US$1-8 per DALY averted**. In contrast, vector control costs have been increasing, as evidenced by the rise in costs for spraying operations from approximately **US$19.62 in 2008 to US$28.90 in 2022 per structure** sprayed [Malaria vector control in sub-Saharan Africa: complex trade ...](https://www.sciencedirect.com/science/article/pii/S2542519624001724) - Web.\n",
      "\n",
      "- Funding for malaria control predominantly comes from global assistance, accounting for **70% of funding for malaria prevention and control** in sub-Saharan Africa. However, despite high levels of external support, progress has stagnated, necessitating a reevaluation of resource allocation and intervention strategies [Global Assistance and the Cascade of Malaria Prevention ...](https://pubmed.ncbi.nlm.nih.gov/40376507/) - Web.\n",
      "\n",
      "### 2. **Trends in Funding and Effectiveness**\n",
      "While initial funding trends showed increases between 2006 and 2011, the plateauing of progress in malaria control despite substantial investments highlights the need for innovative strategies and enhanced operational efficiency [Global funding trends for malaria research in sub-Saharan ...](https://www.sciencedirect.com/science/article/pii/S2214109X17302450) - Web.\n",
      "\n",
      "## Conclusion\n",
      "Global health programs targeting malaria prevention in sub-Saharan Africa have demonstrated significant effectiveness, primarily through a combination of vector control, chemoprevention, health education, and emerging interventions like vaccination. Cost-effectiveness analyses indicate that many interventions are viable options, especially in resource-limited settings. However, ongoing challenges, including rising operational costs and issues related to insecticide resistance, necessitate adaptive strategies and continuous evaluation of interventions.\n",
      "\n",
      "## References\n",
      "1. [Cost-effectiveness of malaria control in sub-Saharan Africa](https://pubmed.ncbi.nlm.nih.gov/10437867/) - Web\n",
      "2. [systematic review and meta-analysis](https://pubmed\n",
      "\n",
      "üìñ Sources Used (30):\n",
      "   1. [WEB] Cost-effectiveness of malaria control in sub-Saharan Africa...\n",
      "   2. [WEB] systematic review and meta-analysis...\n",
      "   3. [WEB] Current Status of Malaria Control and Elimination in Africa...\n",
      "   4. [WEB] Malaria vector control in sub-Saharan Africa: complex trade ...\n",
      "   5. [WEB] Malaria vector control in sub-Saharan Africa: complex trade ...\n"
     ]
    }
   ],
   "source": [
    "question3 = \"How effective are global health programs for malaria prevention in sub-Saharan Africa, and what do recent studies show about cost-effectiveness?\"\n",
    "\n",
    "print(f\"üåç Complex Research Question: {question3}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Use search coordinator for multi-source approach\n",
    "print(\"üîÑ Using Search Coordinator for multi-source research...\")\n",
    "\n",
    "# Create intelligent search plan\n",
    "search_plans = assistant['search_coordinator'].plan_searches(question3, focus=\"\")\n",
    "print(f\"\\nüìã Search Plan Created:\")\n",
    "print(f\"   ‚Ä¢ Search strategies: {len(search_plans)}\")\n",
    "\n",
    "# Execute searches (using the first plan as an example)\n",
    "search_results = assistant['search_coordinator'].execute_search_plan(search_plans[0]) if search_plans else None\n",
    "if search_results:\n",
    "    print(f\"   ‚Ä¢ Web results: {len(search_results.web_results)}\")\n",
    "    print(f\"   ‚Ä¢ Academic results: {len(search_results.arxiv_results)}\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No search results generated\")\n",
    "\n",
    "# Run full MCP research\n",
    "result3 = assistant['mcp_simulator'].run_research(question3)\n",
    "\n",
    "print(\"\\nüìã Multi-Source Research Result:\")\n",
    "print(result3.get('answer', 'No answer generated'))\n",
    "\n",
    "# Show sources used\n",
    "if result3.get('sources'):\n",
    "    print(f\"\\nüìñ Sources Used ({len(result3['sources'])}):\")\n",
    "    for i, source in enumerate(result3['sources'][:5], 1):\n",
    "        source_type = source.get('type', 'unknown')\n",
    "        title = source.get('title', 'Untitled')[:60]\n",
    "        print(f\"   {i}. [{source_type.upper()}] {title}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772079c9",
   "metadata": {},
   "source": [
    "### Demo 4 - Vector Database Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba503779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Testing Vector Database Caching...\n",
      "üîç First-time question: What is the current state of renewable energy adoption globally?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç First-time question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_question\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Check if cached\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m cached_results = \u001b[43massistant\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mvector_db\u001b[39m\u001b[33m'\u001b[39m].similarity_search(cache_question, k=\u001b[32m3\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Cache check: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cached_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m similar entries found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached_results:\n",
      "\u001b[31mNameError\u001b[39m: name 'assistant' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"üíæ Testing Vector Database Caching...\")\n",
    "\n",
    "# Ask a question for the first time\n",
    "cache_question = \"What is the current state of renewable energy adoption globally?\"\n",
    "\n",
    "print(f\"üîç First-time question: {cache_question}\")\n",
    "\n",
    "# Check if cached\n",
    "cached_results = assistant['vector_db'].similarity_search(cache_question, k=3)\n",
    "print(f\"üìä Cache check: {len(cached_results)} similar entries found\")\n",
    "\n",
    "if cached_results:\n",
    "    for i, result in enumerate(cached_results, 1):\n",
    "        similarity = (1 - result.get('distance', 1)) * 100\n",
    "        title = result.get('metadata', {}).get('title', 'Cached Result')\n",
    "        print(f\"   {i}. Similarity: {similarity:.1f}% - {title[:50]}...\")\n",
    "\n",
    "# Run research and cache the result\n",
    "print(\"\\nüî¨ Running fresh research...\")\n",
    "result4 = assistant['mcp_simulator'].run_research(cache_question)\n",
    "\n",
    "# Manually cache this Q&A for demonstration\n",
    "assistant['vector_db'].add_texts(\n",
    "    texts=[cache_question],\n",
    "    metadatas=[{\n",
    "        'title': f\"Q&A: {cache_question[:50]}...\",\n",
    "        'question': cache_question,\n",
    "        'answer': result4.get('answer', ''),\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'sources_count': len(result4.get('sources', []))\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Result cached for future queries\")\n",
    "print(f\"üìã Answer: {result4.get('answer', 'No answer generated')[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e065c9",
   "metadata": {},
   "source": [
    "### Demo 5 - Task Breakdown Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b1d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Demonstrating Task Breakdown for: Compare the environmental impact of electric vehicles versus traditional gasoline cars\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Create a session to see task planning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m session_id = \u001b[43massistant\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmcp_simulator\u001b[39m\u001b[33m'\u001b[39m].create_session(breakdown_question)\n\u001b[32m     10\u001b[39m session = assistant[\u001b[33m'\u001b[39m\u001b[33mmcp_simulator\u001b[39m\u001b[33m'\u001b[39m].sessions[session_id]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Generate task plan\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'assistant' is not defined"
     ]
    }
   ],
   "source": [
    "breakdown_question = \"Compare the environmental impact of electric vehicles versus traditional gasoline cars\"\n",
    "\n",
    "print(f\"üß© Demonstrating Task Breakdown for: {breakdown_question}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a session to see task planning\n",
    "session_id = assistant['mcp_simulator'].create_session(breakdown_question)\n",
    "session = assistant['mcp_simulator'].sessions[session_id]\n",
    "\n",
    "# Generate task plan\n",
    "tasks = assistant['mcp_simulator'].high_level_plan(breakdown_question)\n",
    "session.tasks = tasks\n",
    "\n",
    "print(f\"üìã MCP Simulator broke down the question into {len(tasks)} tasks:\")\n",
    "print()\n",
    "\n",
    "for i, task in enumerate(tasks, 1):\n",
    "    print(f\"Task {i}: {task.task_type.value.upper()}\")\n",
    "    print(f\"   Description: {task.description}\")\n",
    "    print(f\"   Status: {task.status.value}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚ö° Executing tasks step by step:\")\n",
    "print()\n",
    "\n",
    "for i, task in enumerate(tasks, 1):\n",
    "    print(f\"üîÑ Executing Task {i}: {task.task_type.value.upper()}\")\n",
    "    \n",
    "    # Execute the task\n",
    "    task_result = assistant['mcp_simulator'].plan_task(task, session)\n",
    "    \n",
    "    print(f\"   ‚úÖ Completed: {task.description}\")\n",
    "    if isinstance(task_result, dict) and 'summary' in task_result:\n",
    "        print(f\"   üìù Summary: {task_result['summary'][:100]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"üéØ All tasks completed! Final answer available in session.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d630aa8",
   "metadata": {},
   "source": [
    "###  System Performance and Wrap-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Research Assistant Demo Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check vector database stats\n",
    "try:\n",
    "    collection = assistant['vector_db'].collection\n",
    "    total_docs = collection.count()\n",
    "    print(f\"üíæ Vector Database: {total_docs} documents cached\")\n",
    "except:\n",
    "    print(f\"üíæ Vector Database: Ready for use\")\n",
    "\n",
    "# Check session history\n",
    "simulator = assistant['mcp_simulator']\n",
    "total_sessions = len(simulator.sessions)\n",
    "print(f\"üìù Research Sessions: {total_sessions} sessions created\")\n",
    "\n",
    "if simulator.sessions:\n",
    "    latest_session_id = list(simulator.sessions.keys())[-1]\n",
    "    latest_session = simulator.sessions[latest_session_id]\n",
    "    print(f\"üî¨ Latest Session: {latest_session.original_question[:50]}...\")\n",
    "    print(f\"   ‚Ä¢ Tasks completed: {len([t for t in latest_session.tasks if t.status.value == 'completed'])}\")\n",
    "    print(f\"   ‚Ä¢ Sources gathered: {len(latest_session.sources)}\")\n",
    "    print(f\"   ‚Ä¢ Reasoning steps: {len(latest_session.reasoning_steps)}\")\n",
    "\n",
    "print(\"\\nüéØ Key Features Demonstrated:\")\n",
    "features = [\n",
    "    \"‚úÖ Multi-step task decomposition (MCP workflow)\",\n",
    "    \"‚úÖ Web search integration (Tavily API)\",\n",
    "    \"‚úÖ Academic paper search (ArXiv API)\",\n",
    "    \"‚úÖ Vector database caching\",\n",
    "    \"‚úÖ Document processing and analysis\",\n",
    "    \"‚úÖ Multi-source information synthesis\",\n",
    "    \"‚úÖ Source citation and traceability\",\n",
    "    \"‚úÖ Intelligent search planning\"\n",
    "]\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(f\"\\nüöÄ Demo completed successfully!\")\n",
    "print(f\"üí° Try running: `assistant['mcp_simulator'].run_research('your question here')`\")\n",
    "print(f\"üåê Or launch the Gradio interface with: `python src/main.py`\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
